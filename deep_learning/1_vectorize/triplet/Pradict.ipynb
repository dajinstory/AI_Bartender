{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leejungjae/opt/anaconda3/envs/kr2_2_4tf1_13_1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/leejungjae/opt/anaconda3/envs/kr2_2_4tf1_13_1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/leejungjae/opt/anaconda3/envs/kr2_2_4tf1_13_1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/leejungjae/opt/anaconda3/envs/kr2_2_4tf1_13_1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/leejungjae/opt/anaconda3/envs/kr2_2_4tf1_13_1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/leejungjae/opt/anaconda3/envs/kr2_2_4tf1_13_1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "from itertools import permutations\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE=0.00001\n",
    "MARGIN = 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, row, column, channel):\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    filename_train=[]\n",
    "    x_test=[]\n",
    "    y_test=[]\n",
    "    filename_test=[]\n",
    "    # Get directory\n",
    "    DataPaths = [path+'/'+folder_name for folder_name in os.listdir(path)]\n",
    "    print(DataPaths)\n",
    "    # Check each image folders. each image folder contains images with same yoga posture \n",
    "    for label_idx in range(len(DataPaths)):\n",
    "        if os.path.isdir(DataPaths[label_idx]) == False:\n",
    "            continue\n",
    "        LabelPath = DataPaths[label_idx]\n",
    "        \n",
    "        # Check each kinds of data.\n",
    "        ImgPaths = [LabelPath+ '/'+image_name for image_name in os.listdir(LabelPath)]\n",
    "        \n",
    "        #each image\n",
    "        for idx in range(len(ImgPaths)):\n",
    "            imagePath = ImgPaths[idx]\n",
    "            # print(imagePath)\n",
    "            if \".DS_Store\" in imagePath:\n",
    "                continue\n",
    "            img = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
    "            if channel==1:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "            img = cv2.resize(img, (row,column), interpolation = cv2.INTER_AREA)\n",
    "            if idx%4==0:\n",
    "                x_test.append(img)\n",
    "                y_test.append(label_idx)\n",
    "                filename_test.append(imagePath)\n",
    "            else : \n",
    "                x_train.append(img)\n",
    "                y_train.append(label_idx)\n",
    "                filename_train.append(imagePath)\n",
    "    return np.array(x_train), np.array(y_train), filename_train, np.array(x_test), np.array(y_test), filename_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../images/data/1865', '../../images/data/g7', '../../images/data/Barton', '../../images/data/Montes_Alpha', '../../images/data/1', '../../images/data/Diablo', '../../images/data/Canti_Brachetto', '../../images/data/3', '../../images/data/2', '../../images/data/Canti_Moscato']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-caaa75036c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'../../images/data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#사진 1장당 28*28*1 (가로*세로*채널)로 입력된다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#make total data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6154926da98c>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, row, column, channel)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\".DS_Store\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimagePath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#data load\n",
    "img_row=28\n",
    "img_column=28\n",
    "img_channel=1\n",
    "path =  '../../images/data'\n",
    "#사진 1장당 28*28*1 (가로*세로*채널)로 입력된다.\n",
    "x_train, y_train, filename_train, x_test, y_test, filename_test = load_data(path,img_row, img_column, img_channel)\n",
    "#make total data set\n",
    "x_total = np.array(np.concatenate((x_train, x_test), axis = 0))\n",
    "y_total = np.array(np.concatenate((y_train, y_test), axis = 0))\n",
    "filename_total = np.concatenate((filename_train, filename_test), axis = 0)\n",
    "y_total = np.concatenate((y_train,y_test), axis = 0)\n",
    "print(\"before shape : \",x_train.shape, x_test.shape, x_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkImgSet(msg, x_sample, y_sample, filename_sample, classes, maxnum):\n",
    "\n",
    "    print(msg)\n",
    "    for k in range(classes):\n",
    "        plt.figure(figsize=(20,20))\n",
    "    \n",
    "        num=0\n",
    "        for i in range(len(y_sample)):\n",
    "            if num==maxnum:\n",
    "                break\n",
    "            if y_sample[i]==k:\n",
    "                num+=1\n",
    "                plt.subplot(10,10,num)\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.grid(False)\n",
    "                plt.imshow(x_sample[i], cmap='gray', vmin=0, vmax=255)\n",
    "                #plt.imshow(cv2.cvtColor(x_sample[i], cv2.COLOR_BGR2RGB))\n",
    "                plt.xlabel(str(y_sample[i])+filename_sample[i][-10:])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkImgSet(\"Training Samples\", x_train, y_train, filename_train, 10, 5)\n",
    "checkImgSet(\"Validation Samples\", x_test, y_test, filename_test, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"before shape : \",x_train.shape, x_test.shape, x_total.shape)\n",
    "x_train_flat = x_train.reshape(-1,img_row*img_column*img_channel)\n",
    "x_test_flat = x_test.reshape(-1,img_row*img_column*img_channel)                           \n",
    "x_total_flat = x_total.reshape(-1,img_row*img_column*img_channel)\n",
    "print(\"after flat shape : \",x_train_flat.shape, x_test_flat.shape, x_total_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(x, labels, num_of_labels, subtitle=None):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", num_of_labels))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    \n",
    "    \n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[labels.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    # 그래프 규격선, 여백공간 제거\n",
    "    ax.axis('off') \n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(num_of_labels):\n",
    "        # Add Label with txt type on plotting image\n",
    "        xtext, ytext = np.median(x[labels == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "#train_tsne_embeds = tsne.fit_transform(x_train_flat[])\n",
    "#scatter(train_tsne_embeds, y_train[:1641], 10, \"Training Data Before TNN\")\n",
    "\n",
    "eval_tsne_embeds = tsne.fit_transform(x_test_flat)\n",
    "print(eval_tsne_embeds)\n",
    "scatter(eval_tsne_embeds, y_test, 10, \"Validation Data Before TNN\")\n",
    "\n",
    "#total_tsne_embeds = tsne.fit_transform(x_total_flat[:1921])\n",
    "#scatter(total_tsne_embeds, y_total[:1921], 10,\"Total Data Before TNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplet(x,y,ap_pairs=100,an_pairs=100, trainsize=0.7):\n",
    "    data_xy = tuple([x,y])\n",
    "    \n",
    "    triplet_train_pairs = []\n",
    "    triplet_test_pairs = []\n",
    "    \n",
    "    for data_class in sorted(set(data_xy[1])):\n",
    "        same_class_idx = np.where(data_xy[1] == data_class)[0]\n",
    "        diff_class_idx = np.where(data_xy[1] != data_class)[0]\n",
    "        print('same and diff : ', len(same_class_idx), len(diff_class_idx))\n",
    "        \n",
    "        ap_pairs = int((len(same_class_idx) * (len(same_class_idx)-1))/2)\n",
    "        an_pairs = int(len(diff_class_idx))\n",
    "        \n",
    "        #print(\"data_class : \",data_class)\n",
    "        # num of each: ap_pairs, an_pairs\n",
    "        A_P_pairs = random.sample(list(permutations(same_class_idx,2)),ap_pairs) #Generating Anchor-Positive pairs\n",
    "        Neg_idx = random.sample(list(diff_class_idx),an_pairs)\n",
    "        #print(len(A_P_pairs),len(Neg_idx))\n",
    "        #total data: ap_pairs*an_pairs\n",
    "        A_P_len = ap_pairs\n",
    "        Neg_len = an_pairs\n",
    "        ng_idx=0\n",
    "        print('ap' + str(len(A_P_pairs)))\n",
    "        print('neg' + str(len(Neg_idx)))\n",
    "        \n",
    "        \n",
    "        for ap in A_P_pairs[:int(A_P_len)]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            Negative = data_xy[0][Neg_idx[ng_idx%Neg_len]]\n",
    "            if (ng_idx%Neg_len)%4 == 0:\n",
    "                triplet_test_pairs.append([Anchor,Positive,Negative])\n",
    "            else: \n",
    "                triplet_train_pairs.append([Anchor,Positive,Negative])\n",
    "            ng_idx+=1\n",
    "                \n",
    "    return np.array(triplet_train_pairs), np.array(triplet_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_triplet, x_test_triplet = generate_triplet(x_train,y_train,1600,100)\n",
    "print(x_train.shape , x_test.shape)\n",
    "print(x_train_triplet.shape , x_test_triplet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(in_dims):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128,(7,7),padding='same',input_shape=(in_dims[0],in_dims[1],in_dims[2],),activation='relu',name='conv1'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool1'))\n",
    "    model.add(Conv2D(256,(10,10),padding='same',activation='relu',name='conv2'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool2'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(4,name='embeddings'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = MARGIN):\n",
    "    \n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "adam_optim = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None)\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "input_row=28\n",
    "input_column=28\n",
    "input_channel=1\n",
    "anchor_input = Input((input_row, input_column, input_channel, ), name='anchor_input')\n",
    "positive_input = Input((input_row, input_column, input_channel, ), name='positive_input')\n",
    "negative_input = Input((input_row, input_column, input_channel, ), name='negative_input')\n",
    "\n",
    "Shared_DNN =create_base_network([input_row, input_column, input_channel,])\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "model.compile(loss=triplet_loss, optimizer=adam_optim)\n",
    "model.summary()\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "Anchor = x_train_triplet[:,0,:].reshape(-1,input_row, input_column, input_channel)\n",
    "Positive = x_train_triplet[:,1,:].reshape(-1,input_row, input_column, input_channel)\n",
    "Negative = x_train_triplet[:,2,:].reshape(-1,input_row, input_column, input_channel)\n",
    "\n",
    "Anchor_test = x_test_triplet[:,0,:].reshape(-1,input_row, input_column, input_channel)\n",
    "Positive_test = x_test_triplet[:,1,:].reshape(-1,input_row, input_column, input_channel)\n",
    "Negative_test = x_test_triplet[:,2,:].reshape(-1,input_row, input_column, input_channel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "trained_model.load_weights('1.300001-0.1013-27.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_flat = x_train.reshape(-1,img_row*img_column*img_channel)\n",
    "#x_test_flat = x_test.reshape(-1,img_row*img_column*img_channel)                           \n",
    "#x_total_flat = x_total.reshape(-1,img_row*img_column*img_channel)\n",
    "#print(eval_tsne_embeds.shape)\n",
    "tsne = TSNE()\n",
    "X_total_trm = trained_model.predict(x_total.reshape(-1,28,28,1))\n",
    "X_total_trm=X_total_trm.tolist()\n",
    "print(type(X_total_trm))\n",
    "\n",
    "\n",
    "#wine_db.append({'id':i[1], 'filename':i[2], 'vector': i[3], 'label':i[4]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total_trm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_db = []\n",
    "for i in range(len(X_total_trm)):\n",
    "    wine_db.append({'id':i, 'filename': filename_total[i], 'vector': X_total_trm[i], 'label':y_total[i]})\n",
    "#print(wine_db)\n",
    "\n",
    "wine_db_pandas = pd.DataFrame(wine_db)\n",
    "wine_db_pandas.to_csv(\"wine_db_jj.csv\",mode = \"w\",sep=',')\n",
    "#print()\n",
    "\n",
    "#time_pd.to_csv(\"filename.csv\", mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df = pd.DataFrame(list_data,index= )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = pd.read_csv(\"wine_db_dj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr2_2_4tf_1_13_1",
   "language": "python",
   "name": "kr2_2_4tf1_13_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
